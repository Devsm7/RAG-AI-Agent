# ğŸ“ Twuaiq RAG Assistant - FastAPI Edition

A modern, production-ready Retrieval-Augmented Generation (RAG) chatbot for Twuaiq Academy with FastAPI backend, beautiful web interface, and local speech-to-text capabilities.

## âœ¨ Features

### ğŸŒ **Web Interface**
- **Modern UI**: Beautiful, responsive web interface with gradient design
- **Bilingual Support**: Full English/Arabic support with automatic language detection
- **Text Chat**: Type your questions with real-time responses
- **Voice Chat**: Browser-based voice recording with local transcription
- **Session Management**: Separate conversation histories for text and voice
- **Mobile Friendly**: Fully responsive design

### ğŸš€ **FastAPI Backend**
- **REST API**: Professional API endpoints with auto-generated documentation
- **Fast Performance**: Async operations for better concurrency
- **Auto Documentation**: Swagger UI at `/docs` and ReDoc at `/redoc`
- **CORS Enabled**: Ready for frontend integration
- **Health Checks**: Monitor system status

### ğŸ§  **AI Capabilities**
- **Local Embeddings**: HuggingFace multilingual embeddings (offline)
- **Fast Transcription**: faster-whisper for local speech-to-text (2-5 seconds)
- **Vector Search**: ChromaDB for efficient semantic search
- **Context-Aware**: Maintains conversation history
- **Bilingual RAG**: Optimized for English and Arabic queries

## ğŸ“‹ Prerequisites

1. **Python 3.8+** with virtual environment
2. **Ollama** installed with models:
   - `aya:8b` (bilingual chat model)
   - ~~`mxbai-embed-large`~~ (replaced with HuggingFace)
   - ~~`karanchopda333/whisper`~~ (replaced with faster-whisper)

## ğŸš€ Quick Start

### 1. Installation

```bash
# Navigate to project directory
cd c:\Users\user\Desktop\RAG

# Create and activate virtual environment
python -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Install Ollama Model

```bash
# Only need the chat model now
ollama pull aya:8b
```

### 3. Start the Server

**Option 1: Using batch file (easiest)**
```bash
start_fastapi.bat
```

**Option 2: Manual start**
```bash
python app.py
```

### 4. Access the Application

- **Web Interface**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Alternative Docs**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/api/health

## ğŸ“¡ API Endpoints

### 1. **Text Chat** - `/api/chat`

**Request** (JSON):
```json
{
  "message": "What bootcamps are available?",
  "session_id": "my_session"  // optional
}
```

**Response** (JSON):
```json
{
  "response": "The available bootcamps are...",
  "session_id": "my_session"
}
```

**Example (curl)**:
```bash
curl -X POST "http://localhost:8000/api/chat" \
  -H "Content-Type: application/json" \
  -d '{"message": "What bootcamps are available?"}'
```

**Example (Python)**:
```python
import requests

response = requests.post(
    "http://localhost:8000/api/chat",
    json={"message": "What bootcamps are available?"}
)
print(response.json())
```

### 2. **Voice Chat** - `/api/voice-chat`

**Request** (multipart/form-data):
- `audio`: Audio file (WAV format)
- `session_id`: String (optional, default: "voice_session")

**Response** (JSON):
```json
{
  "transcription": "What bootcamps are available?",
  "response": "The available bootcamps are...",
  "session_id": "voice_session"
}
```

**Example (curl)**:
```bash
curl -X POST "http://localhost:8000/api/voice-chat" \
  -F "audio=@recording.wav" \
  -F "session_id=my_voice_session"
```

**Example (Python)**:
```python
import requests

with open("recording.wav", "rb") as audio_file:
    response = requests.post(
        "http://localhost:8000/api/voice-chat",
        files={"audio": audio_file},
        data={"session_id": "my_session"}
    )
print(response.json())
```

### 3. **Clear History** - `/api/clear-history`

**Request** (JSON):
```json
{
  "session_id": "my_session"  // optional
}
```

**Response** (JSON):
```json
{
  "message": "History cleared",
  "session_id": "my_session"
}
```

### 4. **Health Check** - `/api/health`

**Request**: GET (no body)

**Response** (JSON):
```json
{
  "status": "healthy",
  "model": "aya:8b",
  "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2"
}
```

## ğŸ“ Project Structure

```
RAG/
â”œâ”€â”€ app.py                              # FastAPI backend with REST API
â”œâ”€â”€ vector.py                           # Vector store (HuggingFace embeddings)
â”œâ”€â”€ speech_to_text.py                   # faster-whisper transcription
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ start_fastapi.bat                   # Quick start script
â”œâ”€â”€ static/                             # Web interface
â”‚   â”œâ”€â”€ index.html                      # Main HTML page
â”‚   â”œâ”€â”€ styles.css                      # Styling
â”‚   â””â”€â”€ app.js                          # JavaScript logic
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ bootcamps_db.csv               # Bootcamp data
â”‚   â””â”€â”€ places_db.csv                  # Places data
â”œâ”€â”€ chroma_db/                         # Vector database
â”œâ”€â”€ models/                            # HuggingFace model cache
â”œâ”€â”€ FASTER_WHISPER_INTEGRATION.md     # Speech-to-text docs
â””â”€â”€ .venv/                             # Virtual environment
```

## ğŸ”§ How It Works

### Text Chat Flow:
```
User types question â†’ FastAPI â†’ Vector search â†’ RAG â†’ LLM â†’ Response
```

### Voice Chat Flow:
```
Browser records audio â†’ Upload to FastAPI â†’ faster-whisper (local, 2-5s) 
â†’ Transcription â†’ Vector search â†’ RAG â†’ LLM â†’ Response
```

### Key Components:

1. **Embeddings**: HuggingFace `paraphrase-multilingual-MiniLM-L12-v2`
   - 384 dimensions
   - 50+ languages including Arabic
   - Cached locally in `models/`

2. **Speech-to-Text**: faster-whisper `small` model
   - Local transcription (no internet needed)
   - 2-5 second processing time
   - Automatic language detection
   - Voice Activity Detection (VAD)

3. **Chat Model**: Ollama `aya:8b`
   - Bilingual (English/Arabic)
   - Context-aware responses
   - Conversation history

4. **Vector Store**: ChromaDB
   - Semantic search
   - Top-10 retrieval
   - Persistent storage

## ğŸ¨ Web Interface Features

### Text Chat Tab
- Type questions in English or Arabic
- Example questions for quick start
- Real-time responses
- Message history
- Clear conversation button

### Voice Chat Tab
- Browser-based recording (no installation)
- Visual recording indicator
- Automatic transcription
- Same RAG capabilities as text
- Separate session management

## âš™ï¸ Configuration

### Change Whisper Model Size

Edit `app.py` line 23-28:

```python
stt = SpeechToText(
    whisper_model="small",  # tiny/base/small/medium/large-v3
    device="cpu",           # "cuda" for GPU
    compute_type="int8"     # "float16" for GPU
)
```

| Model | Size | Speed | Accuracy |
|-------|------|-------|----------|
| tiny | 75 MB | âš¡âš¡âš¡âš¡âš¡ | â­â­ |
| base | 145 MB | âš¡âš¡âš¡âš¡ | â­â­â­ |
| **small** | 466 MB | âš¡âš¡âš¡ | â­â­â­â­ (recommended) |
| medium | 1.5 GB | âš¡âš¡ | â­â­â­â­â­ |
| large-v3 | 3 GB | âš¡ | â­â­â­â­â­ |

### Change Server Port

Edit `app.py` line 250:

```python
uvicorn.run(
    app,
    host="0.0.0.0",
    port=8000,  # Change this
    log_level="info"
)
```

### Customize UI

- **Colors**: Edit `static/styles.css` (lines 2-20 for CSS variables)
- **Layout**: Edit `static/index.html`
- **Functionality**: Edit `static/app.js`

## ğŸ› Troubleshooting

### Port Already in Use
```bash
# Find process using port 8000
netstat -ano | findstr :8000

# Kill the process
taskkill /PID <PID> /F
```

### Dependencies Missing
```bash
pip install -r requirements.txt
```

### Voice Recording Not Working
- Use Chrome or Edge browser
- Grant microphone permissions
- Ensure you're on localhost or HTTPS

### Ollama Not Responding
```bash
# Start Ollama service
ollama serve

# Verify model is available
ollama list
```

### Slow Transcription
- Try smaller whisper model (base or tiny)
- Use GPU if available (set device="cuda")
- Check CPU usage

## ğŸ“¦ Dependencies

```
langchain                    # LangChain framework
langchain-ollama            # Ollama integration
langchain-chroma            # ChromaDB vector store
langchain-community         # Community integrations
langchain-huggingface       # HuggingFace embeddings
sentence-transformers       # Embedding models
faster-whisper              # Local speech-to-text
fastapi                     # Web framework
uvicorn[standard]           # ASGI server
python-multipart            # File upload support
pandas                      # Data processing
sounddevice                 # Audio recording (for testing)
soundfile                   # Audio file handling
numpy                       # Numerical operations
```

## ğŸ“š Documentation

- **API Docs**: http://localhost:8000/docs (when server is running)
- **faster-whisper Integration**: See `FASTER_WHISPER_INTEGRATION.md`
- **FastAPI**: https://fastapi.tiangolo.com/
- **LangChain**: https://python.langchain.com/

## ğŸš€ Production Deployment

### Using Multiple Workers
```bash
uvicorn app:app --host 0.0.0.0 --port 8000 --workers 4
```

### With HTTPS
```bash
uvicorn app:app --host 0.0.0.0 --port 443 --ssl-keyfile=key.pem --ssl-certfile=cert.pem
```

### Docker Deployment
```bash
docker-compose up -d
```

## ğŸ“ Notes

- **First run**: Vector database and whisper model will be downloaded
- **Offline capable**: Works without internet after initial setup
- **Session management**: Each tab has separate conversation history
- **Auto cleanup**: Temporary audio files are automatically deleted
- **Bilingual**: Automatically detects and responds in the same language

## ğŸ¯ Example Queries

### English
- "What bootcamps are available?"
- "Where is the cafeteria?"
- "What time does the Unity bootcamp start?"
- "Tell me about the Cyber Security bootcamp"

### Arabic
- "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø¹Ø³ÙƒØ±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©ØŸ"
- "Ø£ÙŠÙ† ØªÙ‚Ø¹ Ø§Ù„ÙƒØ§ÙØªÙŠØ±ÙŠØ§ØŸ"
- "Ù…ØªÙ‰ ÙŠØ¨Ø¯Ø£ Ù…Ø¹Ø³ÙƒØ± ÙŠÙˆÙ†ÙŠØªÙŠØŸ"
- "Ø£Ø®Ø¨Ø±Ù†ÙŠ Ø¹Ù† Ù…Ø¹Ø³ÙƒØ± Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ"

## ğŸ“„ License

This project is for educational purposes at Twuaiq Academy.

---

**Built with â¤ï¸ using FastAPI, LangChain, HuggingFace, and faster-whisper**
